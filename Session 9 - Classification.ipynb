{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Steps of Classification\n",
    "\n",
    "# 1. Load Data\n",
    "# 2. Select Features\n",
    "# 3. Data Preprocessing -> FIltering data\n",
    "# 4. Transform Data -> Normalization (Easy to Check Data)\n",
    "# 5. Generate Model\n",
    "# 6. Model test and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "# Import SparkSsession\n",
    "from pyspark.sql import SparkSession\n",
    "# Import the ML Classification -> LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Import Evaluation -> BianryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# Import when (if else condition in pyspark)\n",
    "from pyspark.sql.functions import when\n",
    "# For Normalization import VectortAssembler, StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Create Spark Session\n",
    "\n",
    "spark = SparkSession.builderGetOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 Load Data\n",
    "\n",
    "# Find factor that have a big impact of it's output which is 'Depressed'\n",
    "\n",
    "# Training\n",
    "df_train = spark.read.option(\"inferSchema\", \"true\").csv(\"data/Classification_Train.csv\", header=True)\n",
    "\n",
    "# Testing\n",
    "df_test = spark.read.option(\"inferSchema\", \"true\").csv(\"data/Classification_Test.csv\", header=True)\n",
    "\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 Data Preprocessing\n",
    "\n",
    "# Clean data\n",
    "df_train = df_train.na.drop()\n",
    "df_test = df_test.na.drop()\n",
    "\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 Select Feature (Basically SELECT)\n",
    "\n",
    "# Education Level - Eye Color - Married - Salary Income - Depressed\n",
    "df_train = df_train.select(\"Education Level\", \"Eye Color\", \"Married\", \"Salary Income\", \"Depressed\")\n",
    "\n",
    "df_test = df_test.select(\"Education Level\", \"Eye Color\", \"Married\", \"Salary Income\", \"Depressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 Data Transformation -> Converting Data String into Integer\n",
    "# Must Integer to easy to make the scatter plot\n",
    "\n",
    "# Ex : Education Level : High - Intermediate - Low\n",
    "# Ex 2 : NULL -> YES = 1, NO = 0\n",
    "\n",
    "def transform(df):\n",
    "    df = df.withColumn(\"Education Level\", when(df[\"Education Level\"] ==\"High\", 3).when(df[\"Education Level\"] == \"Intermediate\",2).when(df[\"Education Level\"] == \"Low\", 1))\n",
    "    df = df.withColumn(\"Married\", when(df[\"Married\"] == \"Yes\", 1).when(df[\"Married\"]==\"No\", 0))\n",
    "    df = df.withColumn(\"Depressed\", when(df[\"Depressed\"] == \"Yes\" , 1).when(df[\"Depressed\"] == \"No\", 0))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = transform(df_train)\n",
    "df_test = transform(df_test)\n",
    "\n",
    "# Show it's output\n",
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Dynamic\n",
    "cols = df_train.column\n",
    "cols.remove(\"Depressed\") #Because Depressed is the output\n",
    "\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"Features\")\n",
    "scaler = StandardScaler(inputCol=\"Features\", outputCol=\"ScaledFeatures\")\n",
    "\n",
    "df_train = assembler.transform(df_train)\n",
    "df_train = scaler.fit(df_train).transform(df_train)\n",
    "\n",
    "df_test = assembler.transform(df_test)\n",
    "df_test = scaler.fit(df_test).transform(df_test)\n",
    "\n",
    "df_test.show()\n",
    "\n",
    "# just going to test it\n",
    "test = assembler.transform(df_train)\n",
    "test = scaler.fit(test).transform(test)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Model with LogisticRegression\n",
    "\n",
    "# Compare ScaledFeatures with Depressed\n",
    "model = LogisticRegression(featuresCol=\"ScaledFeatures\", labelCol=\"Depressed\").fit(df_train)\n",
    "# Generate Prediction\n",
    "prediction = model.transform(df_test)\n",
    "prediction.select(\"Depressed\", \"Prediction\", \"ScaledFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Testing and Evaluation\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Depressed\")\n",
    "accuracy = round(evaluator.evaluate(prediction) * 100 ,2)\n",
    "\n",
    "print(f\"{accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
